{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Analiza zbioru: Absenteeism at work\n",
    "Bartłomiej Błaszczyk 236382/209276"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Spis treści:\n",
    "\n",
    "- [1. Eksploracja danych](#1-eksploracja-danych)\n",
    "    - [1.1 Wczytanie danych](#11-wczytanie-danych)\n",
    "    - [1.2 Wstępny podgląd danych](#12-wstępny-podgląd-danych)\n",
    "    - [1.3 Podsumowanie statystyczne](#13-podsumowanie-statystyczne)\n",
    "    - [1.4 Identyfikacja brakujących danych](#14-identyfikacja-brakujących-danych)\n",
    "    - [1.5 Identyfikacja cech](#15-identyfikacja-cech)\n",
    "    - [1.6 Dystrybucja danych](#16-dystrybucja-danych)\n",
    "    - [1.7 Relacje między cechami](#17-relacje-między-cechami)\n",
    "    - [1.8 Wartości odstające](#18-wartości-odstające)\n",
    "    - [1.9 Obserwacje](#19-obserwacje)\n",
    "- [2. Przygotowanie danych do treningu](#2-przygotowanie-danych-do-treningu)\n",
    "    - [2.1 Normalizacja danych](#21-normalizacja-danych)\n",
    "        - [2.1.1 Normalizacja Z-score](#211-normalizacja-z-score-z-użyciem-skalowania-cech-o-dystrybucji-zbliżonej-do-standardowej)\n",
    "        - [2.1.2 Normalizacja Min-Max](#212-normalizacja-min-max-dla-cech-o-rozkładzie-nienormalnym-xd)\n",
    "        - [2.1.3 Kodowanie kategorii](#213-kodowanie-cech-kategorycznych)\n",
    "    - [2.2 Podział na zbiory treningowe i testowe](#22-podział-danych-na-zbiory-testowe-i-treningowe)\n",
    "- [3. Modelowanie](#3-modelowanie)\n",
    "    - [3.1 Pipeline](#31-tworzenie-lejka-danych-do-modelu)\n",
    "    - [3.2 Ewaluacja](#32-ewaluacja-modelu)\n",
    "        - [3.2.1 Confusion Matrix](#321-confusion-matrix)\n",
    "        - [3.2.2 F1-Score](#322-f1-score)\n",
    "        - [3.2.3](#323-roc-auc-score)\n",
    "        - [3.2.4](#324-wnioski)\n",
    "- [4. Konkluzje](#4-konkluzje)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Zrozumienie biznesu\n",
    "## Q: Jakie wyzwanie biznesowe chcesz rozwiązać?\n",
    "### A: Zidentyfikować najważniejszą cechę, która prowadzi do porażki dyscyplinarnej.\n",
    "## Q: Dlaczego to jest ważne?\n",
    "### A: Pomoże to zespołowi reagować lepiej na niepokojące oznaki prowadzące do zwolnienia pracownika.\n",
    "## Q: Co starasz się osiągnąć i jak to będzie mierzone?\n",
    "### A: Chcę doprowadzić do zmniejszenia liczby zwolnień w zesppole.\n",
    "## Q: Ile masz czasu na projekt?\n",
    "### A: Tydzień.\n",
    "## Q: Jak wykorzystasz model/analizy, aby osiągnąć zakładany cel?\n",
    "### A: Przedstawię wskazówki zespołowi HR."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Eksploracja danych"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.1 Wczytanie danych"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "raw_data_path = \"../data/raw/absenteeism_at_work.csv\"\n",
    "df = pd.read_csv(raw_data_path, delimiter=\";\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.2 Wstępny podgląd danych\n",
    "- Rozmiary tabeli.\n",
    "- Pierwsze i ostatnie rzędy."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f\"Dataset contains {df.shape[0]} rows and {df.shape[1]} columns.\")\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.tail()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.3 Podsumowanie statystyczne\n",
    "- Dane statystyczne.\n",
    "- Metadane o tabeli."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.4 Identyfikacja brakujących danych."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "missing_values = df.isnull().sum()\n",
    "print(missing_values)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Brak brakujących danych"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.5 Identyfikacja cech\n",
    "\n",
    "Podczas identyfikacji tworzę kopię zbioru df (Data Frame) do zmiennej dfc (Data Frame Categorical), żeby móc łatwiej rozpoznać zależności na wykresach."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import textwrap\n",
    "dfc = df.copy()\n",
    "\n",
    "df.hist(bins=30, figsize=(15, 10))\n",
    "plt.suptitle('Generyczne histogramy')\n",
    "plt.show()\n",
    "\n",
    "icd_mapping = {\n",
    "    1: \"Certain infectious and parasitic diseases\",\n",
    "    2: \"Neoplasms\",\n",
    "    3: \"Diseases of the blood and blood-forming organs and certain disorders involving the immune mechanism\",\n",
    "    4: \"Endocrine, nutritional and metabolic diseases\",\n",
    "    5: \"Mental and behavioural disorders\",\n",
    "    6: \"Diseases of the nervous system\",\n",
    "    7: \"Diseases of the eye and adnexa\",\n",
    "    8: \"Diseases of the ear and mastoid process\",\n",
    "    9: \"Diseases of the circulatory system\",\n",
    "    10: \"Diseases of the respiratory system\",\n",
    "    11: \"Diseases of the digestive system\",\n",
    "    12: \"Diseases of the skin and subcutaneous tissue\",\n",
    "    13: \"Diseases of the musculoskeletal system and connective tissue\",\n",
    "    14: \"Diseases of the genitourinary system\",\n",
    "    15: \"Pregnancy, childbirth and the puerperium\",\n",
    "    16: \"Certain conditions originating in the perinatal period\",\n",
    "    17: \"Congenital malformations, deformations and chromosomal abnormalities\",\n",
    "    18: \"Symptoms, signs and abnormal clinical and laboratory findings, not elsewhere classified\",\n",
    "    19: \"Injury, poisoning and certain other consequences of external causes\",\n",
    "    20: \"External causes of morbidity and mortality\",\n",
    "    21: \"Factors influencing health status and contact with health services\",\n",
    "    22: \"Patient follow-up\",\n",
    "    23: \"Medical consultation\",\n",
    "    24: \"Blood donation\",\n",
    "    25: \"Laboratory examination\",\n",
    "    26: \"Unjustified absence\",\n",
    "    27: \"Physiotherapy\",\n",
    "    28: \"Dental consultation\"\n",
    "}\n",
    "\n",
    "icd_order = list(icd_mapping.values())\n",
    "\n",
    "months_mapping = {\n",
    "    1: 'January', 2: 'February', 3: 'March', 4: 'April', 5: 'May', 6: 'June', 7: 'July', 8: 'August', 9: 'September', 10: 'October', 11: 'November', 12: 'December'\n",
    "}\n",
    "\n",
    "months_order = list(months_mapping.values())\n",
    "\n",
    "days_mapping = {\n",
    "    2: 'Monday', 3: 'Tuesday', 4: 'Wednesday', 5: 'Thursday', 6: 'Friday',\n",
    "    7: 'Saturday', 1: 'Sunday'\n",
    "}\n",
    "\n",
    "days_order = list(days_mapping.values())\n",
    "\n",
    "seasons_mapping = {\n",
    "    1: 'Summer', 2: 'Autumn', 3: 'Winter', 4: 'Spring'\n",
    "}\n",
    "\n",
    "seasons_order = list(seasons_mapping.values())\n",
    "\n",
    "education_mapping = {\n",
    "    1: 'High school', 2: 'Graduate', 3: 'Postgraduate', 4: 'Master and Doctor'\n",
    "}\n",
    "\n",
    "education_order = list(education_mapping.values())\n",
    "\n",
    "binary_mapping = {\n",
    "    0: 'No', 1: 'Yes'\n",
    "}\n",
    "\n",
    "binary_order = ['No', 'Yes']\n",
    "\n",
    "dfc['Reason for absence'] = dfc['Reason for absence'].replace(icd_mapping)\n",
    "dfc['Reason for absence'] = pd.Categorical(dfc['Reason for absence'], categories=icd_order, ordered=True)\n",
    "\n",
    "dfc['Month of absence'] = dfc['Month of absence'].replace(months_mapping)\n",
    "dfc['Month of absence'] = pd.Categorical(dfc['Month of absence'], categories=months_order, ordered=True)\n",
    "\n",
    "dfc['Day of the week'] = dfc['Day of the week'].replace(days_mapping)\n",
    "dfc['Day of the week'] = pd.Categorical(dfc['Day of the week'], categories=days_order, ordered=True)\n",
    "\n",
    "dfc['Seasons'] = dfc['Seasons'].replace(seasons_mapping)\n",
    "dfc['Seasons'] = pd.Categorical(dfc['Seasons'], categories=seasons_order, ordered=True)\n",
    "\n",
    "dfc['Education'] = dfc['Education'].replace(education_mapping)\n",
    "dfc['Education'] = pd.Categorical(dfc['Education'], categories=education_order, ordered=True)\n",
    "\n",
    "dfc['Disciplinary failure'] = dfc['Disciplinary failure'].replace(binary_mapping)\n",
    "dfc['Disciplinary failure'] = pd.Categorical(dfc['Disciplinary failure'], categories=binary_order, ordered=True)\n",
    "\n",
    "dfc['Social drinker'] = dfc['Social drinker'].replace(binary_mapping)\n",
    "dfc['Social drinker'] = pd.Categorical(dfc['Social drinker'], categories=binary_order, ordered=True)\n",
    "\n",
    "dfc['Social smoker'] = dfc['Social smoker'].replace(binary_mapping)\n",
    "dfc['Social smoker'] = pd.Categorical(dfc['Social smoker'], categories=binary_order, ordered=True)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "ax = dfc['Reason for absence'].value_counts().reindex(dfc['Reason for absence'].cat.categories).plot(kind='bar')\n",
    "plt.title('Histogram for Reason for Absence')\n",
    "plt.xlabel('Reason for Absence')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "labels = [textwrap.fill(label, 30) for label in dfc['Reason for absence'].cat.categories]\n",
    "ax.set_xticklabels(labels, rotation=90, ha='right', fontsize=8)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "categorical_columns = ['Day of the week', 'Seasons', 'Month of absence', 'Education', 'Disciplinary failure', 'Social drinker', 'Social smoker']\n",
    "\n",
    "n_cols = 4\n",
    "n_rows = (len(categorical_columns) + n_cols - 1) // n_cols\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(16, 4 * n_rows))\n",
    "\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, column in enumerate(categorical_columns):\n",
    "    ax = axes[i]\n",
    "    dfc[column].value_counts().reindex(dfc[column].cat.categories).plot(kind='bar', ax=ax)\n",
    "    ax.set_title(f'Histogram for {column}')\n",
    "    ax.set_xlabel(column)\n",
    "    ax.set_ylabel('Count')\n",
    "\n",
    "    labels = [textwrap.fill(label, 30) for label in dfc[column].cat.categories]\n",
    "    ax.set_xticklabels(labels, rotation=15, ha='right', fontsize=7)\n",
    "\n",
    "for j in range(len(categorical_columns), len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.6 Dystrybucja danych"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_columns = len(df.select_dtypes(include=['float64', 'int64']).columns)\n",
    "fig, axes = plt.subplots(nrows=(num_columns // 3) + 1, ncols=3, figsize=(15, 10))  # Adjusting grid size\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, column in enumerate(df.select_dtypes(include=['float64', 'int64']).columns):\n",
    "    sns.boxplot(x=df[column], ax=axes[i])\n",
    "    axes[i].set_title(f'Box Plot of {column}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.7 Relacje między cechami"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "colors = [(1, 0.8, 0.8), (0, 0, 0), (1, 0.8, 0.8)]\n",
    "n_bins = 100\n",
    "cmap_name = 'pink_white_pink'\n",
    "cmap = LinearSegmentedColormap.from_list(cmap_name, colors, N=n_bins)\n",
    "\n",
    "correlation_matrix = df.corr()\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap=cmap, vmin=-1, vmax=1, center=0, fmt=\".2f\")\n",
    "plt.title('Mapa cieplna korelacji')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Na wykresie korelacji nie widać zależności, ktróre mogły by wskazywać na silne powiązania między dwoma cechami"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.8 Wartości odstające"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "z_scores = np.abs(stats.zscore(df.select_dtypes(include=[np.number])))\n",
    "outliers = (z_scores > 3).sum(axis=0)\n",
    "print(f'Liczba wartości odstających dla danej cechy:\\n{outliers}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.9 Obserwacje"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.9.1 Reason for absence i Disciplinary failure\n",
    "\n",
    "Źródło danych nie opisuje kategorii 'Reason_for_absence_0', ale można wnioskować, że chodzi o nieobecność spowodowaną zwolnieniem. Trenując model należy wykluczyć 'Reason_for_absence_0' ze zbioru."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "crosstab_data = pd.crosstab(df['Reason for absence'], df['Disciplinary failure'])\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "crosstab_data.plot(kind='bar', stacked=True, color=['skyblue', 'orange'])\n",
    "\n",
    "plt.title('Stacked Bar Plot of Reasons for Absence by Disciplinary Failure')\n",
    "plt.xlabel('Reason for Absence')\n",
    "plt.ylabel('Number of Occurrences')\n",
    "plt.xticks(rotation=45, ha='right', fontsize=8)\n",
    "plt.legend(title='Disciplinary Failure', loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2 Przygotowanie danych do treningu"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.1 Normalizacja danych\n",
    "\n",
    "### 2.1.1 Standaryzacja (normalizacja Z-score):\n",
    "\n",
    "Podczas korzystania ze StandardScaler (normalizacji Z-score), dane są przekształcane w taki sposób, że:\n",
    "Średnia skalowanych danych wynosi 0.\n",
    "Odchylenie standardowe wynosi 1.\n",
    "Odpowiednia, gdy dane są rozkładem normalnym.\n",
    "\n",
    "### 2.1.2 Skalowanie min-max:\n",
    "\n",
    "Skaluje dane do ustalonego zakresu, zazwyczaj [0, 1].\n",
    "Odpowiednia, gdy dane nie mają rozkładu normalnego.\n",
    "\n",
    "### Obsługa zmiennych kategorycznych\n",
    "\n",
    "Modele nie mogą bezpośrednio obsługiwać zmiennych kategorycznych. Kodowanie pozwala na przekształcenie tych zmiennych w liczby, które mogą być użyte przez algorytmy takie jak regresja liniowa, drzewa decyzyjne, czy sieci neuronowe. Za pomocą przekształcenia kategorii danej cechy w kolumny typu binarnego możemy zakodować informację o występowaniu danej kategorii. Tworzy to dodatkową liczbę cech reprezentujące wszystkie kategorie. Takie kodowanie nazywa się One-Hot.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "df_scaled = df.copy()\n",
    "\n",
    "z_score_features = ['Distance from Residence to Work', 'Service time', 'Age', 'Son', 'Pet', 'Weight', 'Height', 'Body mass index', 'Work load Average/day ']\n",
    "min_max_features = ['Transportation expense', 'Hit target', 'Absenteeism time in hours']\n",
    "categorical_features = ['Reason for absence', 'Day of the week', 'Seasons', 'Month of absence', 'Education', 'Disciplinary failure', 'Social drinker', 'Social smoker']\n",
    "\n",
    "df_scaled.columns"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.1.1 Normalizacja Z-score z użyciem skalowania cech o dystrybucji zbliżonej do standardowej"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "z_scaler = StandardScaler()\n",
    "df_scaled[z_score_features] = z_scaler.fit_transform(df[z_score_features])\n",
    "df_scaled.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.1.2 Normalizacja Min-Max dla cech o rozkładzie nienormalnym xD"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mm_scaler = MinMaxScaler()\n",
    "df_scaled[min_max_features] = mm_scaler.fit_transform(df[min_max_features])\n",
    "df_scaled.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.1.3 Kodowanie cech kategorycznych\n",
    "\n",
    "Użycie drop_first=True:\n",
    "\n",
    "Używanie drop_first=True jest wskazne pracując z modelami o charakterystyce liniowej, gdy kategorie rozbite na poszczególne cechy tworzą oczywiste zależności liniowe między sobą. Pozbycie się pierwszej kategori z każdej cechy pprzy rozbiciu pozwala zminimalizować wpływ zaistnienia tego zjawiska przy modelowaniu liniowym."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_scaled = pd.get_dummies(df_scaled, columns=categorical_features, drop_first=True)\n",
    "df_scaled.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Wszystkie kategorie zostały rozbite na cechy. Zbiór danych teraz posiada dodatkowe kolumny które reprezentują obecność lub brak kategori."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_scaled.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.2 Podział danych na zbiory testowe i treningowe\n",
    "\n",
    "Disciplinary failure jest zmienną którą będę próbował przewidzieć."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ze wzgledu na użycie narzędzia ColumnTransformer przy modelowaniu, nie będę używał ręcznie stworzonej zmiennej ```df_scaled``` do podziału na zbiory.\n",
    "\n",
    "Przed podziałem następuje usunięcie kolummny ID, oraz targetu ze zbioru treningowego, oraz wybranie cechy jako \"target\".\n",
    "\n",
    "Usuwam ze zbioru również cechę 'Reason for absence', ze względu na to, że kategoria 'Reason_for_absence_0' prawie bezpośrednio implikuje wystąpienie 'Disciplinary_failure_true'\n",
    "\n",
    "Po wybraniu cech następuje podział 80/20 do treningu i testowania modelu."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X = df.drop(columns=['Disciplinary failure', 'ID', 'Reason for absence', 'Absenteeism time in hours'])\n",
    "y = df['Disciplinary failure']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Zdefiniowanie cech liczbowych i kategorycznych"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_features = X.select_dtypes(include=['object', 'category']).columns.tolist()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3 Modelowanie\n",
    "\n",
    "Ze względu na różnorodność danych i brak możliwości skalowania do jednej wartosci wybrałem model random forest, który jest dobry do klasyfikacji binarnej - Disciplinary failure (tak/nie).\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.1 Tworzenie lejka danych do modelu\n",
    "\n",
    "Uzycie zmiennej drop='first' nie szkodzi użyciu modelu Random Forest, a pozwoli na skuteczne użycie Regresji Liniowej."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(drop='first'), categorical_features)\n",
    "    ])\n",
    "\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pipeline.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.2 Ewaluacja modelu"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_pred = pipeline.predict(X_test)\n",
    "y_prob = pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "roc_auc = roc_auc_score(y_test, y_prob)\n",
    "print(f\"ROC-AUC Score: {roc_auc:.2f}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.2.1 Confusion Matrix\n",
    "\n",
    "(TN): 139 przypadków, w których model poprawnie przewidział \"Brak naruszenia dyscypliny.\"\n",
    "(FP): 1 przypadek, w którym model błędnie przewidział \"Naruszenie dyscypliny\", kiedy go nie było.\n",
    "(FN): 0 przypadków, w których model błędnie przewidział \"Brak naruszenia dyscypliny\", kiedy ono wystąpiło.\n",
    "(TP): 8 przypadków, w których model poprawnie przewidział \"Naruszenie dyscypliny.\"\n",
    "\n",
    "Wszystkie 139 negatywnych przewidywań jest poprawnych, a tylko 1 jest niepoprawnie sklasyfikowane.\n",
    "Model poprawnie zidentyfikował 99% wszystkich faktycznych negatywów.\n",
    "Spośród wszystkich przypadków przewidzianych jako \"True\" (Naruszenie dyscypliny), 89% jest poprawnych.\n",
    "Model poprawnie zidentyfikował wszystkie faktyczne przypadki \"True\" (8 na 8).\n",
    "\n",
    "### 3.2.2 F1-Score\n",
    "\n",
    "Łączy precyzję i czułość w jednym wskaźniku. Dla \"False\" (Brak naruszenia dyscypliny) wynosi 1.00, a dla \"True\" (Naruszenie dyscypliny) wynosi 0.94. Średnia F1 macro wynosi 0.97, a średnia ważona F1 wynosi 0.99, co wskazuje na dobrą równowagę między precyzją a czułością.\n",
    "\n",
    "### 3.2.3 ROC-AUC score\n",
    "\n",
    "Wynik ROC-AUC 1.00 wskazuje na idealne rozdzielenie klas. Oznacza to, że model doskonale rozróżnia \"Naruszenie dyscypliny\" i \"Brak naruszenia dyscypliny.\"\n",
    "The overall accuracy is 99%, indicating the model correctly predicts 99% of the cases.\n",
    "Imbalanced Data Consideration:\n",
    "\n",
    "### 3.2.4 Wnioski\n",
    "\n",
    "Tylko 8 z 148 próbek ma \"Naruszenie dyscypliny\" (True). Sugeruje to, że zbiór danych jest silnie niezrównoważony, z bardzo nielicznymi przypadkami \"Naruszenia dyscypliny\". Choć model wykazuje doskonałą czułość dla klasy mniejszościowej (wszystkie 8 przypadków zostało poprawnie zidentyfikowanych), może to wynikać z tego, że model skutecznie nauczył się wzorców ze względu na mały rozmiar klasy mniejszościowej.\n",
    "\n",
    "Model działa wyjątkowo dobrze na bieżącym zbiorze danych, ale należy zachować ostrożność w kontekście przeuczenia, zwłaszcza ze względu na niezrównoważenie klas. Zaleca się dalszą ocenę przy użyciu różnych zbiorów danych lub walidacji krzyżowej, aby potwierdzić odporność modelu."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.3 Klasyfikacja istotności cech modelu"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "feature_importances = pipeline.named_steps['classifier'].feature_importances_\n",
    "feature_names = pipeline.named_steps['preprocessor'].get_feature_names_out()\n",
    "feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_importance_df['Feature'], feature_importance_df['Importance'])\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Feature Importance from Random Forest')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4. Konkluzje\n",
    "\n",
    "Najważniejszym predyktorem porażnki w dyscyplinowaniu pracownika jest fakt, czy miał już on na koncie dużo godzin nieobecności. Jest to oczywisty wniosek, dlatego lepiej się przyjżeć wynikom modelu usuwając z parametrów nieobecnośc w godzinach w kroku 2.2:\n",
    "\n",
    "```X = df.drop(columns=['Disciplinary failure', 'ID', 'Reason for absence', 'Absenteeism time in hours'])```\n",
    "\n",
    "Po usunięciu cechy widzimy wciąż bardzo dobre wyniki modelu. Patrząc na wykres współczynników istotności możemy domyślać się, że:\n",
    "- „Dzień tygodnia” pozostaje kluczowym predyktorem, prawdopodobnie dlatego, że spotkania lub rozmowy dotyczące działań dyscyplinarnych lub zwolnień są strategicznie planowane na konkretne dni, takie jak piątki lub poniedziałki. Może to być działanie mające na celu zarządzanie wpływem na morale zespołu lub codzienne operacje.\n",
    "- Wysokie średnie obciążenie pracą dziennie może prowadzić do wypalenia zawodowego, niezadowolenia lub obniżonego morale pracowników, co zwiększa prawdopodobieństwo problemów dyscyplinarnych. Z kolei niskie obciążenie pracą może oznaczać słabą wydajność lub brak zaangażowania, co również może prowadzić do negatywnych konsekwencji dla pracowników.\n",
    "- Umiejętność osiągania wyznaczonych celów jest kluczowa. Pracownicy, którzy regularnie nie realizują tych celów, mogą spotkać się z konsekwencjami, w tym działaniami dyscyplinarnymi lub ostatecznym zwolnieniem. To wyraźny wskaźnik, że wskaźniki wydajności są ściśle monitorowane i cenione przez organizację.\n",
    "- Wyższe koszty transportu mogą zniechęcać pracowników do regularnego przychodzenia do pracy, zwłaszcza jeśli koszty te są znaczące w stosunku do ich dochodów. Może to prowadzić do nieobecności, które pośrednio mogą przyczynić się do niepowodzeń dyscyplinarnych lub decyzji dotyczących zwolnień.\n",
    "- Znaczenie „Miesiąca” może być związane ze zmianami sezonowymi, przeglądami końcoworocznymi lub cyklami budżetowymi, które zbieżają się z redukcjami etatów lub zwiększoną kontrolą wydajności pracowników. Może również pokrywać się z czasem wdrażania zmian organizacyjnych, takich jak restrukturyzacja lub wprowadzanie nowych polityk.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
